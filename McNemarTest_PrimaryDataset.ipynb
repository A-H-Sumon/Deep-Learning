{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-H-Sumon/Deep-Learning/blob/main/McNemarTest_PrimaryDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "95686169"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.feature import hog\n",
        "from skimage.filters import gabor\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "from termcolor import colored\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-kr1iv78nqUM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VPga7XY3ISRm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bea446c1",
        "outputId": "5f144008-f49a-447f-b675-44a9d9f274d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/My Drive/dataset.csv\", dtype=str)  # Ensure paths are read as strings\n",
        "\n",
        "# Define features and labels\n",
        "X = df[\"image_path\"]  # Image paths\n",
        "y = df[\"label\"].astype(int)  # Labels as integers\n",
        "\n",
        "# Split into 80% training, 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y, shuffle=True)\n",
        "\n",
        "# Create DataFrames\n",
        "train_df = pd.DataFrame({\"image_path\": X_train, \"label\": y_train})\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/test_df.csv')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tVMbNwAdnSSr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['label'].unique())  # Check unique labels in the dataset\n",
        "print(df['label'].nunique())  # Check the number of unique classes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frWuQ6q11XVW",
        "outputId": "f1ddf071-de85-47b9-ff57-02cbb9151926"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f8da4f0",
        "outputId": "bbdc5382-f4cf-4c57-c1af-c60b097459b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training images: 1672\n",
            "Total testing images: 418\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total training images: {len(train_df)}\")\n",
        "print(f\"Total testing images: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1c163614"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import cv2.ximgproc as xip\n",
        "\n",
        "def preprocess_image(file_path):\n",
        "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        return np.zeros((28, 28))  # Placeholder for missing images\n",
        "\n",
        "    # Apply Otsu's Thresholding\n",
        "    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Resize image to 28x28\n",
        "    img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA) / 255.0\n",
        "\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================== Load & Preprocess Images ========================\n",
        "train_images = np.array([preprocess_image(fp) for fp in train_df['image_path'].values])"
      ],
      "metadata": {
        "id": "M9io7DBwNbGK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0c9f1f30"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "from joblib import Parallel, delayed\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "def augment_image(img):\n",
        "    rows, cols = img.shape\n",
        "\n",
        "\n",
        "\n",
        "    # Random Rotation\n",
        "    angle = random.uniform(-15, 15)\n",
        "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
        "    rotated = cv2.warpAffine(img, M, (cols, rows))\n",
        "\n",
        "    # Random Shifting\n",
        "    tx = random.uniform(-2, 2)\n",
        "    ty = random.uniform(-2, 2)\n",
        "    M_shift = np.float32([[1, 0, tx], [0, 1, ty]])\n",
        "    shifted = cv2.warpAffine(rotated, M_shift, (cols, rows))\n",
        "\n",
        "    return shifted\n",
        "\n",
        "def augment_dataset(train_images):\n",
        "    \"\"\"Applies augmentation to a dataset using parallel processing.\"\"\"\n",
        "    num_cores = multiprocessing.cpu_count()\n",
        "    augmented_images = Parallel(n_jobs=num_cores)(\n",
        "        delayed(augment_image)(img) for img in train_images\n",
        "    )\n",
        "    return np.array(augmented_images)\n",
        "\n",
        "# Apply augmentation to dataset\n",
        "augmented_images = augment_dataset(train_images)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['label'] = test_df['label'].astype(str)\n",
        "\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',  # Include labels here\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',  # Ensure class mode is categorical\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7kW4xjFSvyd",
        "outputId": "60b333af-316e-4328-980f-f47507a7f530"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 418 validated image filenames belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cores = multiprocessing.cpu_count()\n",
        "print(cores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVdthSUnGwyg",
        "outputId": "590c64d6-fd18-428c-fa1c-953f829fb600"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install mahotas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8zA8_UCPXMD",
        "outputId": "be45249d-fd53-452d-9558-ff70d4a5ecd3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mahotas\n",
            "  Downloading mahotas-1.4.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mahotas) (2.0.2)\n",
            "Downloading mahotas-1.4.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mahotas\n",
            "Successfully installed mahotas-1.4.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9060b8d6"
      },
      "outputs": [],
      "source": [
        "from joblib import Parallel, delayed\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "from skimage.feature import hog, local_binary_pattern\n",
        "from skimage.filters import gabor\n",
        "from mahotas.features import zernike_moments\n",
        "\n",
        "# Feature Extraction\n",
        "def extract_features_single(img):\n",
        "     # Extract HOG features\n",
        "    hog_features = hog(img, pixels_per_cell=(4, 4), cells_per_block=(2, 2), feature_vector=True)\n",
        "\n",
        "    # Extract Gabor features\n",
        "    gabor_response_real, gabor_response_imag = gabor(img, frequency=0.6)\n",
        "    gabor_features = np.mean(gabor_response_real) + np.mean(gabor_response_imag)\n",
        "\n",
        "    # Extract LBP features\n",
        "    lbp = local_binary_pattern(img, P=8, R=1, method=\"uniform\")\n",
        "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 10))\n",
        "    lbp_hist = lbp_hist.astype(\"float\")\n",
        "    lbp_hist /= lbp_hist.sum()  # Normalize LBP histogram\n",
        "\n",
        "    return np.hstack([hog_features, gabor_features, lbp_hist])\n",
        "\n",
        "def extract_features(images):\n",
        "    num_cores = multiprocessing.cpu_count()\n",
        "    features = Parallel(n_jobs=num_cores)(delayed(extract_features_single)(img) for img in images)\n",
        "    return np.array(features)\n",
        "\n",
        "# Apply feature extraction\n",
        "augmented_features = extract_features(augmented_images)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5c02952b"
      },
      "outputs": [],
      "source": [
        "# ======================== Data Preparation ========================\n",
        "X_train_preprocessed = np.array([preprocess_image(fp) for fp in train_df['image_path']])\n",
        "X_test_preprocessed = np.array([preprocess_image(fp) for fp in test_df['image_path']])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply augmentation\n",
        "X_train_augmented = augment_dataset(X_train_preprocessed)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nsq32NpNTfXP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from augmented images\n",
        "X_train_features = extract_features(X_train_augmented)\n",
        "X_test_features = extract_features(X_test_preprocessed)  # No augmentation for test set"
      ],
      "metadata": {
        "id": "exrR8qUkTfZ7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "77d5a6f4"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_features = scaler.fit_transform(X_train_features)\n",
        "X_test_features = scaler.transform(X_test_features)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(train_df['label'])\n",
        "y_test = encoder.fit_transform(test_df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1fd3216e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786c0f6c-458c-499f-abf9-3bf81733d665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.4 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "def load_images(image_paths):\n",
        "    data = []\n",
        "    for path in image_paths:\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
        "        img = cv2.resize(img, (64, 64))  # Resize to a fixed size\n",
        "        img = img.flatten()  # Convert to 1D array\n",
        "        data.append(img)\n",
        "    return np.array(data)\n",
        "\n",
        "# Assuming X_train originally contains image file paths\n",
        "X_train = load_images(X_train)\n"
      ],
      "metadata": {
        "id": "GE7IHILLiyvx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(trial):\n",
        "    \"\"\"Objective function for optimizing KNN hyperparameters.\"\"\"\n",
        "\n",
        "    # Hyperparameters to optimize\n",
        "    k = trial.suggest_int('n_neighbors', 3, 15)  # Number of neighbors\n",
        "    metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'minkowski'])\n",
        "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
        "\n",
        "    # Initialize KNN classifier\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k, metric=metric, weights=weights)\n",
        "\n",
        "    # Perform cross-validation to get accuracy\n",
        "    score = cross_val_score(knn_model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
        "\n",
        "    return score  # Return the mean cross-validation accuracy"
      ],
      "metadata": {
        "id": "lv5AK_wjiamz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study_knn = optuna.create_study(direction='maximize')  # Maximize accuracy\n",
        "study_knn.optimize(objective, n_trials=50)  # Run 50 trials\n",
        "\n",
        "# Get the best parameters\n",
        "best_knn_params = study_knn.best_params\n",
        "print(\"Best KNN hyperparameters:\", best_knn_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whSJfi1oV0vl",
        "outputId": "12ab7527-9aeb-44e1-c9cc-344d68bf0f9d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-18 17:19:50,136] A new study created in memory with name: no-name-09b13307-3599-4b53-b6b1-3f0b43c18fa6\n",
            "[I 2025-07-18 17:19:51,298] Trial 0 finished with value: 0.7775082670479935 and parameters: {'n_neighbors': 3, 'metric': 'euclidean', 'weights': 'uniform'}. Best is trial 0 with value: 0.7775082670479935.\n",
            "[I 2025-07-18 17:19:52,551] Trial 1 finished with value: 0.7912628474394495 and parameters: {'n_neighbors': 8, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:19:54,050] Trial 2 finished with value: 0.7697434980784699 and parameters: {'n_neighbors': 8, 'metric': 'minkowski', 'weights': 'uniform'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:19:56,303] Trial 3 finished with value: 0.7822915363303244 and parameters: {'n_neighbors': 15, 'metric': 'euclidean', 'weights': 'distance'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:19:58,316] Trial 4 finished with value: 0.7864831530967915 and parameters: {'n_neighbors': 10, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:20:21,500] Trial 5 finished with value: 0.7583841272678523 and parameters: {'n_neighbors': 7, 'metric': 'manhattan', 'weights': 'uniform'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:20:32,119] Trial 6 finished with value: 0.7817034587541335 and parameters: {'n_neighbors': 6, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:20:34,286] Trial 7 finished with value: 0.7793118241129682 and parameters: {'n_neighbors': 5, 'metric': 'euclidean', 'weights': 'uniform'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:20:36,386] Trial 8 finished with value: 0.7757136473322014 and parameters: {'n_neighbors': 6, 'metric': 'minkowski', 'weights': 'uniform'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:20:46,742] Trial 9 finished with value: 0.7733327375100545 and parameters: {'n_neighbors': 11, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:20:48,618] Trial 10 finished with value: 0.7864831530967915 and parameters: {'n_neighbors': 13, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:20:50,520] Trial 11 finished with value: 0.7846921083206722 and parameters: {'n_neighbors': 11, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:20:52,398] Trial 12 finished with value: 0.7864831530967915 and parameters: {'n_neighbors': 10, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:20:53,543] Trial 13 finished with value: 0.7864920904459737 and parameters: {'n_neighbors': 9, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:20:54,472] Trial 14 finished with value: 0.7912628474394495 and parameters: {'n_neighbors': 8, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 1 with value: 0.7912628474394495.\n",
            "[I 2025-07-18 17:20:55,414] Trial 15 finished with value: 0.7924533023505228 and parameters: {'n_neighbors': 4, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 15 with value: 0.7924533023505228.\n",
            "[I 2025-07-18 17:20:56,365] Trial 16 finished with value: 0.7942532844758243 and parameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:20:57,319] Trial 17 finished with value: 0.7942532844758243 and parameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:08,482] Trial 18 finished with value: 0.7739261774957548 and parameters: {'n_neighbors': 3, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:09,388] Trial 19 finished with value: 0.7924533023505228 and parameters: {'n_neighbors': 4, 'metric': 'euclidean', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:10,323] Trial 20 finished with value: 0.7936526946107785 and parameters: {'n_neighbors': 5, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:11,252] Trial 21 finished with value: 0.7942532844758243 and parameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:12,196] Trial 22 finished with value: 0.7942532844758243 and parameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:13,136] Trial 23 finished with value: 0.7924533023505228 and parameters: {'n_neighbors': 4, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:14,078] Trial 24 finished with value: 0.7936526946107785 and parameters: {'n_neighbors': 5, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:15,018] Trial 25 finished with value: 0.7942532844758243 and parameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:16,052] Trial 26 finished with value: 0.7757136473322014 and parameters: {'n_neighbors': 6, 'metric': 'minkowski', 'weights': 'uniform'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:17,014] Trial 27 finished with value: 0.7924533023505228 and parameters: {'n_neighbors': 4, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:17,927] Trial 28 finished with value: 0.7936526946107785 and parameters: {'n_neighbors': 5, 'metric': 'euclidean', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:29,145] Trial 29 finished with value: 0.7535883456966663 and parameters: {'n_neighbors': 3, 'metric': 'manhattan', 'weights': 'uniform'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:30,070] Trial 30 finished with value: 0.7924604522298687 and parameters: {'n_neighbors': 7, 'metric': 'euclidean', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:31,059] Trial 31 finished with value: 0.7942532844758243 and parameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:32,000] Trial 32 finished with value: 0.7942532844758243 and parameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:32,931] Trial 33 finished with value: 0.7924533023505228 and parameters: {'n_neighbors': 4, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:34,746] Trial 34 finished with value: 0.7942532844758243 and parameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:38,407] Trial 35 finished with value: 0.7924533023505228 and parameters: {'n_neighbors': 4, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:39,788] Trial 36 finished with value: 0.7793118241129682 and parameters: {'n_neighbors': 5, 'metric': 'minkowski', 'weights': 'uniform'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:40,728] Trial 37 finished with value: 0.7846813835016535 and parameters: {'n_neighbors': 14, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:41,678] Trial 38 finished with value: 0.794247922066315 and parameters: {'n_neighbors': 6, 'metric': 'euclidean', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:52,733] Trial 39 finished with value: 0.7583841272678523 and parameters: {'n_neighbors': 7, 'metric': 'manhattan', 'weights': 'uniform'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:54,406] Trial 40 finished with value: 0.7942532844758243 and parameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:55,389] Trial 41 finished with value: 0.7942532844758243 and parameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:56,302] Trial 42 finished with value: 0.7924533023505228 and parameters: {'n_neighbors': 4, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:57,251] Trial 43 finished with value: 0.7942532844758243 and parameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:58,183] Trial 44 finished with value: 0.7936526946107785 and parameters: {'n_neighbors': 5, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:21:59,139] Trial 45 finished with value: 0.7924533023505228 and parameters: {'n_neighbors': 4, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:22:00,084] Trial 46 finished with value: 0.7942532844758243 and parameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:22:11,350] Trial 47 finished with value: 0.7512020734650102 and parameters: {'n_neighbors': 12, 'metric': 'manhattan', 'weights': 'uniform'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:22:12,283] Trial 48 finished with value: 0.794247922066315 and parameters: {'n_neighbors': 6, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n",
            "[I 2025-07-18 17:22:13,209] Trial 49 finished with value: 0.7924533023505228 and parameters: {'n_neighbors': 4, 'metric': 'minkowski', 'weights': 'distance'}. Best is trial 16 with value: 0.7942532844758243.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best KNN hyperparameters: {'n_neighbors': 3, 'metric': 'minkowski', 'weights': 'distance'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract best values\n",
        "best_k = best_knn_params['n_neighbors']\n",
        "best_metric = best_knn_params['metric']\n",
        "best_weights = best_knn_params['weights']\n",
        "\n",
        "def knn(X_train, y_train, X_test, k=best_k, metric=best_metric, weights=best_weights):\n",
        "    \"\"\"Optimized KNN model.\"\"\"\n",
        "\n",
        "    # Convert labels to NumPy array (avoid indexing issues)\n",
        "    y_train = np.array(y_train)\n",
        "\n",
        "    # Fit KNN classifier with optimized parameters\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k, metric=metric, weights=weights)\n",
        "    knn_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on test set\n",
        "    predictions = knn_model.predict(X_test)\n",
        "\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "c0hY__1DV0x6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5e3ed9be"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Run KNN with optimized parameters\n",
        "knn_preds = knn(X_train_features, y_train, X_test_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7502eed8"
      },
      "outputs": [],
      "source": [
        "X_train_combined = np.hstack((X_train_features, y_train.reshape(-1, 1)))\n",
        "X_test_combined = np.hstack((X_test_features, knn_preds.reshape(-1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "feature_dim = X_train_combined.shape[1]  # Assuming X_train is your feature matrix\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    \"\"\"Objective function for optimizing neural network hyperparameters.\"\"\"\n",
        "\n",
        "    # Hyperparameters to optimize\n",
        "    num_units_1 = trial.suggest_int('num_units_1', 128, 512, step=64)  # First Dense layer\n",
        "    num_units_2 = trial.suggest_int('num_units_2', 64, 256, step=64)   # Second Dense layer\n",
        "    num_units_3 = trial.suggest_int('num_units_3', 32, 128, step=32)   # Third Dense layer\n",
        "    dropout_1 = trial.suggest_float('dropout_1', 0.2, 0.5)  # Dropout after first layer\n",
        "    dropout_2 = trial.suggest_float('dropout_2', 0.2, 0.5)  # Dropout after second layer\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 0.0001, 0.001)  # Adam learning rate\n",
        "\n",
        "    # Build model\n",
        "    model = Sequential([\n",
        "        Dense(num_units_1, activation='selu', input_shape=(feature_dim,)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(dropout_1),\n",
        "        Dense(num_units_2, activation='selu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(dropout_2),\n",
        "        Dense(num_units_3, activation='selu'),\n",
        "        BatchNormalization(),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile model with tuned learning rate\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train model (Use fewer epochs for tuning)\n",
        "    history = model.fit(\n",
        "        X_train_combined, y_train,\n",
        "        epochs=10,  # Keep epochs low for tuning\n",
        "        batch_size=64,\n",
        "        validation_split=0.2,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Return best validation accuracy\n",
        "    return max(history.history['val_accuracy'])\n"
      ],
      "metadata": {
        "id": "IDTsEzYyUVA_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "e4631237",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61d3932-1fc3-4fad-c637-f726a1306a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-18 17:22:13,428] A new study created in memory with name: no-name-b18e6da8-7803-4d69-b705-fb1782f3fca8\n",
            "/tmp/ipython-input-25-3243621785.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 0.0001, 0.001)  # Adam learning rate\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "[I 2025-07-18 17:22:20,431] Trial 0 finished with value: 0.8656716346740723 and parameters: {'num_units_1': 256, 'num_units_2': 192, 'num_units_3': 32, 'dropout_1': 0.4138291953492418, 'dropout_2': 0.36730184729743615, 'learning_rate': 0.0007526265546120398}. Best is trial 0 with value: 0.8656716346740723.\n",
            "[I 2025-07-18 17:22:30,307] Trial 1 finished with value: 0.8686566948890686 and parameters: {'num_units_1': 384, 'num_units_2': 256, 'num_units_3': 128, 'dropout_1': 0.3787890282822862, 'dropout_2': 0.45056710775711095, 'learning_rate': 0.0003697709893910396}. Best is trial 1 with value: 0.8686566948890686.\n",
            "[I 2025-07-18 17:22:38,626] Trial 2 finished with value: 0.8298507332801819 and parameters: {'num_units_1': 128, 'num_units_2': 256, 'num_units_3': 64, 'dropout_1': 0.4837222145805461, 'dropout_2': 0.464196633431561, 'learning_rate': 0.0002680125281697044}. Best is trial 1 with value: 0.8686566948890686.\n",
            "[I 2025-07-18 17:22:47,678] Trial 3 finished with value: 0.8477612137794495 and parameters: {'num_units_1': 512, 'num_units_2': 128, 'num_units_3': 96, 'dropout_1': 0.34433550498313026, 'dropout_2': 0.34364711498898876, 'learning_rate': 0.00015202737329811573}. Best is trial 1 with value: 0.8686566948890686.\n",
            "[I 2025-07-18 17:22:55,847] Trial 4 finished with value: 0.8179104328155518 and parameters: {'num_units_1': 192, 'num_units_2': 256, 'num_units_3': 64, 'dropout_1': 0.4729936704990674, 'dropout_2': 0.47448239970776596, 'learning_rate': 0.00012254057696687836}. Best is trial 1 with value: 0.8686566948890686.\n",
            "[I 2025-07-18 17:23:04,417] Trial 5 finished with value: 0.8507462739944458 and parameters: {'num_units_1': 448, 'num_units_2': 192, 'num_units_3': 32, 'dropout_1': 0.42645963938942894, 'dropout_2': 0.21281150709969632, 'learning_rate': 0.00062120122353291}. Best is trial 1 with value: 0.8686566948890686.\n",
            "[I 2025-07-18 17:23:11,975] Trial 6 finished with value: 0.874626874923706 and parameters: {'num_units_1': 256, 'num_units_2': 256, 'num_units_3': 32, 'dropout_1': 0.296562540668884, 'dropout_2': 0.37969089745618384, 'learning_rate': 0.0007442252439897629}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:23:21,809] Trial 7 finished with value: 0.8567163944244385 and parameters: {'num_units_1': 448, 'num_units_2': 128, 'num_units_3': 96, 'dropout_1': 0.29546112848696876, 'dropout_2': 0.25331508280127035, 'learning_rate': 0.0006773868767459636}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:23:28,128] Trial 8 finished with value: 0.8597015142440796 and parameters: {'num_units_1': 128, 'num_units_2': 64, 'num_units_3': 32, 'dropout_1': 0.43363268636166086, 'dropout_2': 0.21326175939330339, 'learning_rate': 0.0007961968975496724}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:23:36,478] Trial 9 finished with value: 0.8567163944244385 and parameters: {'num_units_1': 128, 'num_units_2': 192, 'num_units_3': 64, 'dropout_1': 0.31120791780888435, 'dropout_2': 0.4319363748173013, 'learning_rate': 0.0008930110806910024}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:23:42,874] Trial 10 finished with value: 0.8626865744590759 and parameters: {'num_units_1': 320, 'num_units_2': 64, 'num_units_3': 128, 'dropout_1': 0.20666385162214798, 'dropout_2': 0.33797956943271185, 'learning_rate': 0.00034419689907091647}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:23:52,115] Trial 11 finished with value: 0.8626865744590759 and parameters: {'num_units_1': 320, 'num_units_2': 256, 'num_units_3': 128, 'dropout_1': 0.2521300544176479, 'dropout_2': 0.4010577407405733, 'learning_rate': 0.0004029598500073537}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:24:00,443] Trial 12 finished with value: 0.8567163944244385 and parameters: {'num_units_1': 384, 'num_units_2': 256, 'num_units_3': 96, 'dropout_1': 0.36892191742529573, 'dropout_2': 0.40736448523341606, 'learning_rate': 0.0002268722143321624}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:24:08,232] Trial 13 finished with value: 0.874626874923706 and parameters: {'num_units_1': 256, 'num_units_2': 256, 'num_units_3': 128, 'dropout_1': 0.37104304694501916, 'dropout_2': 0.29150372169709254, 'learning_rate': 0.0004555908310107081}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:24:16,329] Trial 14 finished with value: 0.8567163944244385 and parameters: {'num_units_1': 256, 'num_units_2': 192, 'num_units_3': 64, 'dropout_1': 0.28906413843016426, 'dropout_2': 0.29135539413695843, 'learning_rate': 0.0005011288713800423}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:24:24,046] Trial 15 finished with value: 0.8537313342094421 and parameters: {'num_units_1': 256, 'num_units_2': 256, 'num_units_3': 96, 'dropout_1': 0.3371244533104661, 'dropout_2': 0.30136350636576015, 'learning_rate': 0.0005132687099279012}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:24:32,468] Trial 16 finished with value: 0.8716418147087097 and parameters: {'num_units_1': 192, 'num_units_2': 128, 'num_units_3': 32, 'dropout_1': 0.24734998550770818, 'dropout_2': 0.2972233435296598, 'learning_rate': 0.0009718106604194301}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:24:38,533] Trial 17 finished with value: 0.8597015142440796 and parameters: {'num_units_1': 192, 'num_units_2': 192, 'num_units_3': 128, 'dropout_1': 0.3939419270164697, 'dropout_2': 0.3797738853102067, 'learning_rate': 0.0005003074100582089}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:24:47,165] Trial 18 finished with value: 0.8507462739944458 and parameters: {'num_units_1': 256, 'num_units_2': 256, 'num_units_3': 96, 'dropout_1': 0.26585030678958277, 'dropout_2': 0.3328859461960756, 'learning_rate': 0.00019489074297171242}. Best is trial 6 with value: 0.874626874923706.\n",
            "[I 2025-07-18 17:24:56,538] Trial 19 finished with value: 0.874626874923706 and parameters: {'num_units_1': 384, 'num_units_2': 192, 'num_units_3': 64, 'dropout_1': 0.3163876855412334, 'dropout_2': 0.4985558404528181, 'learning_rate': 0.0005816874039159316}. Best is trial 6 with value: 0.874626874923706.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'num_units_1': 256, 'num_units_2': 256, 'num_units_3': 32, 'dropout_1': 0.296562540668884, 'dropout_2': 0.37969089745618384, 'learning_rate': 0.0007442252439897629}\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction='maximize')  # Maximize accuracy\n",
        "study.optimize(objective, n_trials=20)  # Run 20 trials\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = study.best_params\n",
        "print(\"Best hyperparameters:\", best_params)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unpack Optuna best parameters\n",
        "num_units_1 = best_params['num_units_1']\n",
        "num_units_2 = best_params['num_units_2']\n",
        "num_units_3 = best_params['num_units_3']\n",
        "dropout_1 = best_params['dropout_1']\n",
        "dropout_2 = best_params['dropout_2']\n",
        "learning_rate = best_params['learning_rate']\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "\n",
        "# ====================== EfficientNet-B0 ============================\n",
        "# Load predictions if previously saved\n",
        "efficientnet_preds = np.load(\"/content/drive/My Drive/test_predictions.npy\")\n",
        "\n",
        "# ====================== FusionNet Predictions ======================\n",
        "# Rebuild final FusionNet model using best hyperparameters\n",
        "final_model = Sequential([\n",
        "    Dense(num_units_1, activation='selu', input_shape=(X_train_combined.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(dropout_1),\n",
        "    Dense(num_units_2, activation='selu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(dropout_2),\n",
        "    Dense(num_units_3, activation='selu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "final_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                    loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train on full training data\n",
        "final_model.fit(X_train_combined, y_train, epochs=20, batch_size=64, verbose=0)\n",
        "\n",
        "# Predict on test set\n",
        "fusionnet_preds_proba = final_model.predict(X_test_combined)\n",
        "fusionnet_preds = np.argmax(fusionnet_preds_proba, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "test_df['label'] = test_df['label'].astype(str)\n",
        "\n",
        "true_labels = test_generator.labels  # Already aligned\n",
        "# ====================== Contingency Table ======================\n",
        "fusionnet_correct = fusionnet_preds == true_labels\n",
        "efficientnet_correct = efficientnet_preds == true_labels\n",
        "\n",
        "B = np.sum((fusionnet_correct == True) & (efficientnet_correct == False))  # FusionNet correct, EfficientNet wrong\n",
        "C = np.sum((fusionnet_correct == False) & (efficientnet_correct == True))  # EfficientNet correct, FusionNet wrong\n",
        "\n",
        "# Create table\n",
        "table = [[0, B],\n",
        "         [C, 0]]\n",
        "\n",
        "# Run McNemar's Test\n",
        "result = mcnemar(table, exact=False, correction=True)\n",
        "\n",
        "# ====================== Output ======================\n",
        "print(\"\\n========= McNemar’s Test Result =========\")\n",
        "print(f\"Contingency Table: [[0, {B}], [{C}, 0]]\")\n",
        "print(f\"McNemar's Test Statistic: {result.statistic:.4f}\")\n",
        "print(f\"P-value:  {result.pvalue:.4f}\")\n",
        "\n",
        "if result.pvalue > 0.05:\n",
        "    print(\" No statistically significant difference between FusionNet and EfficientNet-B0.\")\n",
        "else:\n",
        "    print(\" Statistically significant difference between the two models.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB7EgQnxVa6w",
        "outputId": "07a1fcdc-a0ba-44c2-f922-eb259195a87d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\n",
            "========= McNemar’s Test Result =========\n",
            "Contingency Table: [[0, 19], [39, 0]]\n",
            "McNemar's Test Statistic: 6.2241\n",
            "P-value:  0.0126\n",
            " Statistically significant difference between the two models.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}